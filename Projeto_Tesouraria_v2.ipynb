{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 1: Ingestão e Exploração Inicial dos Dados\n# =============================================================================\n# Dataset: Olist Brazilian E-Commerce (Kaggle)\n# Tabelas carregadas neste módulo:\n#   olist_orders_dataset.csv         -> ciclo de vida dos pedidos\n#   olist_order_payments_dataset.csv -> meios e valores de pagamento\n# Esta célula inspeciona a estrutura bruta antes de qualquer transformação.\n# =============================================================================\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nCAMINHO = r'C:\\Users\\alexandre.souza\\Desktop\\trabalho\\github\\tesourara'\n\ndf_orders   = pd.read_csv(rf'{CAMINHO}\\olist_orders_dataset.csv')\ndf_payments = pd.read_csv(rf'{CAMINHO}\\olist_order_payments_dataset.csv')\n\nfor nome, df in [('PEDIDOS', df_orders), ('PAGAMENTOS', df_payments)]:\n    print('=' * 80)\n    print(f'TABELA DE {nome} — Shape: {df.shape} | Nulos: {df.isnull().sum().sum()}')\n    print('=' * 80)\n    print(df.head(3).to_string())\n    print()\n    df.info()\n    print()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 2: Tratamento de Tipos, Limpeza e Join\n# =============================================================================\n# Etapas:\n#   1. Conversão de colunas de data: object -> datetime64\n#   2. Filtro de elegibilidade financeira\n#   3. Join das tabelas de pedidos e pagamentos via order_id\n#\n# Critérios de exclusão:\n#   order_approved_at nulo   -> pedido sem evento financeiro reconhecível\n#   order_status == canceled -> sem direito a recebível\n# =============================================================================\n\ncolunas_data = [\n    'order_purchase_timestamp', 'order_approved_at',\n    'order_delivered_carrier_date', 'order_delivered_customer_date',\n    'order_estimated_delivery_date'\n]\nfor col in colunas_data:\n    df_orders[col] = pd.to_datetime(df_orders[col])\n\nn_antes = len(df_orders)\ndf_validos = df_orders.dropna(subset=['order_approved_at'])\ndf_validos = df_validos[df_validos['order_status'] != 'canceled']\nn_depois   = len(df_validos)\nprint(f'Pedidos removidos pelo filtro: {n_antes - n_depois:,} ({(n_antes-n_depois)/n_antes*100:.1f}%)')\n\ndf_tesouraria = pd.merge(\n    df_validos[['order_id', 'order_status', 'order_approved_at']],\n    df_payments,\n    on='order_id',\n    how='inner'\n)\ndf_tesouraria['data_aprovacao'] = df_tesouraria['order_approved_at'].dt.normalize()\n\nprint(f'Tabela unificada: {df_tesouraria.shape[0]:,} linhas x {df_tesouraria.shape[1]} colunas')\nprint(df_tesouraria.head().to_string())\n\ndist = df_tesouraria['payment_type'].value_counts().to_frame('transacoes')\ndist['pct'] = (dist['transacoes'] / dist['transacoes'].sum() * 100).round(1)\nprint('\\nDISTRIBUICAO POR MEIO DE PAGAMENTO:')\nprint(dist.to_string())\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 3: Projeção de Recebíveis (Inflow) — Desdobramento de Parcelas\n# =============================================================================\n# Regras de liquidação por meio de pagamento (premissas de modelagem):\n#\n#   MEIO              LIQUIDAÇÃO    OBSERVAÇÃO\n#   Boleto            D+2           Compensação na rede bancária\n#   Débito            D+1           Liquidação via rede de débito\n#   Voucher           D+0           Compensação imediata\n#   Crédito (parcela) D+30*n        Cada parcela liquidada em múltiplos de 30d\n#\n# NOTA: valores BRUTOS. O fluxo líquido exige desconto do MDR (Merchant\n# Discount Rate) de cada operadora. Em produção, datas vêm da adquirente.\n# =============================================================================\nimport pandas as pd\nimport numpy as np\n\ndf_proj = df_tesouraria.copy()\ndf_proj['data_aprovacao'] = pd.to_datetime(df_proj['data_aprovacao'])\n\ndf_cc     = df_proj[df_proj['payment_type'] == 'credit_card'].copy()\ndf_outros = df_proj[df_proj['payment_type'] != 'credit_card'].copy()\n\n# Liquidacao: Boleto, Debito, Voucher\ndias_liq = {'boleto': 2, 'debit_card': 1, 'voucher': 0}\ndf_outros['dias_liq']         = df_outros['payment_type'].map(dias_liq).fillna(0).astype(int)\ndf_outros['data_recebimento'] = df_outros['data_aprovacao'] + pd.to_timedelta(df_outros['dias_liq'], unit='D')\ndf_outros['valor_recebido']   = df_outros['payment_value']\ndf_outros['parcela_atual']    = 1\n\n# Liquidacao: Cartao de Credito — parcela minima = 1 previne divisao por zero\ndf_cc['payment_installments'] = df_cc['payment_installments'].clip(lower=1)\ndf_cc['parcela_atual'] = df_cc['payment_installments'].apply(lambda n: list(range(1, int(n)+1)))\ndf_cc_exp = df_cc.explode('parcela_atual').copy()\ndf_cc_exp['parcela_atual']    = df_cc_exp['parcela_atual'].astype(int)\ndf_cc_exp['valor_recebido']   = df_cc_exp['payment_value'] / df_cc_exp['payment_installments']\ndf_cc_exp['dias_liq']         = df_cc_exp['parcela_atual'] * 30\ndf_cc_exp['data_recebimento'] = df_cc_exp['data_aprovacao'] + pd.to_timedelta(df_cc_exp['dias_liq'], unit='D')\n\ndf_fluxo_caixa = pd.concat([df_outros, df_cc_exp], ignore_index=True)\ndf_fluxo_caixa = df_fluxo_caixa.sort_values(['data_aprovacao', 'order_id', 'parcela_atual'])\n\npedido = '47770eb9100c2d0c44946d9cf07ec65d'\ncols   = ['order_id', 'payment_type', 'payment_installments',\n          'parcela_atual', 'data_aprovacao', 'data_recebimento', 'valor_recebido']\nprint('=' * 100)\nprint(f'DESDOBRAMENTO DE PARCELAS — Pedido: {pedido}')\nprint('=' * 100)\nprint(df_fluxo_caixa[df_fluxo_caixa['order_id'] == pedido][cols].to_string(index=False))\n\ntot_orig = df_proj['payment_value'].sum()\ntot_proj = df_fluxo_caixa['valor_recebido'].sum()\nok = abs(tot_orig - tot_proj) < 0.01\nprint(f'\\nRECONCILIACAO FINANCEIRA:')\nprint(f'  Transacoes originais  : {len(df_proj):>10,}')\nprint(f'  Recebiveis projetados : {len(df_fluxo_caixa):>10,}')\nprint(f'  Total original   (R$) : {tot_orig:>15,.2f}')\nprint(f'  Total projetado  (R$) : {tot_proj:>15,.2f}')\nprint(f'  Status               : {chr(10003) if ok else \"ATENCAO: divergencia\"}')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 4: Estimativa de Saídas (Outflow)\n# =============================================================================\n# Componentes de outflow modelados:\n#   Frete (freight_value) : custo integral, saída no D+0 da aprovação\n#   Repasse ao Seller     : (1 - take_rate) * valor dos itens\n#\n# Limitações deste modelo simplificado:\n#   - MDR e tarifas bancárias não incluídos\n#   - Devoluções e estornos não modelados\n#   - Saídas reais devem ser extraídas do ERP/financeiro em produção\n# =============================================================================\nimport pandas as pd\n\nCAMINHO   = r'C:\\Users\\alexandre.souza\\Desktop\\trabalho\\github\\tesourara'\nTAKE_RATE = 0.10\n\ntry:\n    df_items = pd.read_csv(rf'{CAMINHO}\\olist_order_items_dataset.csv')\n\n    ids_validos       = df_tesouraria['order_id'].unique()\n    df_items_filtrado = df_items[df_items['order_id'].isin(ids_validos)]\n\n    df_out = df_items_filtrado.groupby('order_id').agg(\n        frete_total = ('freight_value', 'sum'),\n        valor_itens = ('price', 'sum')\n    ).reset_index()\n\n    df_out['repasse_seller'] = df_out['valor_itens'] * (1 - TAKE_RATE)\n    df_out['receita_plat']   = df_out['valor_itens'] * TAKE_RATE\n    df_out['total_saidas']   = df_out['frete_total'] + df_out['repasse_seller']\n\n    df_out = df_out.merge(\n        df_tesouraria[['order_id', 'data_aprovacao']].drop_duplicates(),\n        on='order_id', how='left'\n    )\n    df_out['data_aprovacao'] = pd.to_datetime(df_out['data_aprovacao'])\n\n    df_saidas_diarias = (\n        df_out.groupby('data_aprovacao')['total_saidas']\n        .sum().rename('total_saidas_BRL').sort_index()\n    )\n\n    _outflow_ok = True\n    print('Arquivo de itens carregado com sucesso.')\n    print(f'  Pedidos mapeados             : {len(df_out):,}')\n    print(f'  Total Frete          (R$)    : {df_out[\"frete_total\"].sum():>15,.2f}')\n    print(f'  Total Repasse Sellers(R$)    : {df_out[\"repasse_seller\"].sum():>15,.2f}')\n    print(f'  Total Saidas Estim.  (R$)    : {df_out[\"total_saidas\"].sum():>15,.2f}')\n    print(f'  Receita Plataforma   (R$)    : {df_out[\"receita_plat\"].sum():>15,.2f}  (take rate {TAKE_RATE*100:.0f}%)')\n\nexcept FileNotFoundError:\n    _outflow_ok       = False\n    df_saidas_diarias = None\n    print('=' * 70)\n    print('AVISO: olist_order_items_dataset.csv nao encontrado.')\n    print('=' * 70)\n    print(f'  Caminho esperado: {CAMINHO}\\\\olist_order_items_dataset.csv')\n    print('  Download: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce')\n    print('  Modulos seguintes executarao apenas com inflow projetado.')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 5: Consolidação do Vetor de Liquidez Diária\n# =============================================================================\n# Objetivo: agregar o inflow por data e canal, incorporar as saídas estimadas\n# e gerar o saldo líquido e acumulado — base de todas as análises seguintes.\n# =============================================================================\nimport pandas as pd\n\n# Agregacao do inflow: data x canal\ndf_caixa_diario = (\n    df_fluxo_caixa\n    .groupby(['data_recebimento', 'payment_type'])['valor_recebido']\n    .sum().reset_index()\n)\n\ndf_rel = df_caixa_diario.pivot(\n    index='data_recebimento', columns='payment_type', values='valor_recebido'\n).fillna(0)\ndf_rel.columns.name = None\ndf_rel['total_entradas_BRL'] = df_rel.sum(axis=1)\ndf_rel = df_rel.round(2).sort_index()\ndf_rel.index = pd.to_datetime(df_rel.index)\n\n# Incorporacao do outflow e calculo do saldo\nif _outflow_ok and df_saidas_diarias is not None:\n    df_saldo = df_rel[['total_entradas_BRL']].join(df_saidas_diarias, how='outer').fillna(0)\nelse:\n    df_saldo = df_rel[['total_entradas_BRL']].copy()\n    df_saldo['total_saidas_BRL'] = 0.0\n\ndf_saldo['saldo_liquido_BRL']   = df_saldo['total_entradas_BRL'] - df_saldo['total_saidas_BRL']\ndf_saldo['saldo_acumulado_BRL'] = df_saldo['saldo_liquido_BRL'].cumsum()\n\ndf_relatorio_caixa = df_rel\n\nprint('=' * 100)\nprint('VETOR DE LIQUIDEZ DIARIA — Primeiros 10 dias com movimentacao:')\nprint('=' * 100)\nprint(df_rel.head(10).to_string())\n\nprint('\\n' + '=' * 70)\nprint('ESTATISTICAS DO FLUXO DE CAIXA PROJETADO:')\nprint('=' * 70)\nprint(f'  Periodo         : {df_rel.index.min().date()} -> {df_rel.index.max().date()}')\nprint(f'  Dias c/ entrada : {len(df_rel):,}')\nprint(f'  Media diaria    : R$ {df_rel[\"total_entradas_BRL\"].mean():,.2f}')\nprint(f'  Pico maximo     : R$ {df_rel[\"total_entradas_BRL\"].max():,.2f}')\nprint(f'  Total inflow    : R$ {df_rel[\"total_entradas_BRL\"].sum():,.2f}')\n\nif _outflow_ok:\n    print(f'  Total outflow   : R$ {df_saldo[\"total_saidas_BRL\"].sum():,.2f}')\n    print(f'  Saldo liquido   : R$ {df_saldo[\"saldo_liquido_BRL\"].sum():,.2f}')\n    print(f'  Saldo acum final: R$ {df_saldo[\"saldo_acumulado_BRL\"].iloc[-1]:,.2f}')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 6: Análise de Aging de Recebíveis\n# =============================================================================\n# A curva de aging classifica os recebíveis futuros em faixas de vencimento\n# para dimensionar o capital de giro em cada horizonte temporal.\n#\n# Faixas (a partir da data de referência 31/07/2018):\n#   1. Até 7 dias  -> caixa imediato\n#   2. 8–15 dias   -> curto prazo\n#   3. 16–30 dias  -> médio prazo (1 mês)\n#   4. 31–60 dias  -> médio prazo (2 meses)\n#   5. > 60 dias   -> longo prazo / parcelas futuras de cartão\n# =============================================================================\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\n\nDATA_REF = pd.to_datetime('2018-07-31')\n\ndf_aging = df_fluxo_caixa[\n    pd.to_datetime(df_fluxo_caixa['data_recebimento']) > DATA_REF\n].copy()\ndf_aging['data_recebimento']  = pd.to_datetime(df_aging['data_recebimento'])\ndf_aging['dias_para_receber'] = (df_aging['data_recebimento'] - DATA_REF).dt.days\n\ndef faixa_aging(d):\n    if   d <=  7: return '1. Ate 7 dias'\n    elif d <= 15: return '2. 8-15 dias'\n    elif d <= 30: return '3. 16-30 dias'\n    elif d <= 60: return '4. 31-60 dias'\n    else:         return '5. > 60 dias'\n\ndf_aging['faixa_aging'] = df_aging['dias_para_receber'].apply(faixa_aging)\n\nresumo = (\n    df_aging.groupby(['faixa_aging', 'payment_type'])['valor_recebido']\n    .sum().unstack(fill_value=0)\n)\nresumo['Total'] = resumo.sum(axis=1)\n\nsns.set_theme(style='whitegrid')\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\ncanais = [c for c in resumo.columns if c != 'Total']\ncores  = {'boleto': '#ff9f43', 'credit_card': '#54a0ff', 'debit_card': '#2ecc71', 'voucher': '#ee5253'}\nbot    = pd.Series(0.0, index=resumo.index)\nfor canal in canais:\n    axes[0].bar(resumo.index, resumo[canal], bottom=bot,\n                label=canal, color=cores.get(canal, '#aaa'), alpha=0.85)\n    bot += resumo[canal]\naxes[0].set_title('Aging de Recebiveis por Canal', fontsize=13, fontweight='bold')\naxes[0].set_ylabel('Volume Financeiro (R$)')\naxes[0].set_xlabel('Faixa de Vencimento')\naxes[0].tick_params(axis='x', rotation=20)\naxes[0].legend(title='Canal')\naxes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'R${x/1e6:.1f}M'))\n\ntot  = resumo['Total'].values\nacum = [tot[:i+1].sum() / tot.sum() * 100 for i in range(len(tot))]\naxes[1].plot(resumo.index, acum, marker='o', color='#1f77b4', linewidth=2.5)\nfor x, y in zip(resumo.index, acum):\n    axes[1].annotate(f'{y:.1f}%', (x, y), textcoords='offset points',\n                     xytext=(0, 10), fontsize=10, ha='center')\naxes[1].set_title('Concentracao Acumulada de Liquidez', fontsize=13, fontweight='bold')\naxes[1].set_ylabel('% do Volume Total a Receber')\naxes[1].set_xlabel('Faixa de Vencimento')\naxes[1].set_ylim(0, 115)\naxes[1].tick_params(axis='x', rotation=20)\n\nplt.suptitle(f'Aging de Recebiveis — Referencia: {DATA_REF.date()}', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\ntotal_fut = resumo['Total'].sum()\nate7  = resumo.loc[resumo.index == '1. Ate 7 dias',  'Total'].sum()\nate30 = resumo.loc[resumo.index <= '3. 16-30 dias',  'Total'].sum()\nate60 = resumo.loc[resumo.index <= '4. 31-60 dias',  'Total'].sum()\n\nprint('=' * 80)\nprint(f'RELATORIO DE AGING — Referencia: {DATA_REF.date()}')\nprint('=' * 80)\nprint(resumo.to_string())\nprint('\\n' + '-' * 80)\nprint(f'  Total de recebiveis futuros (R$): {total_fut:>15,.2f}')\nprint(f'  Proximos  7 dias           (R$): {ate7:>15,.2f}  ({ate7/total_fut*100:.1f}%)')\nprint(f'  Proximos 30 dias           (R$): {ate30:>15,.2f}  ({ate30/total_fut*100:.1f}%)')\nprint(f'  Proximos 60 dias           (R$): {ate60:>15,.2f}  ({ate60/total_fut*100:.1f}%)')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 7: Visualização Analítica da Série Temporal de Caixa\n# =============================================================================\n# Graficos produzidos:\n#   1. Inflow diario com media movel de 7 dias (tendencia estrutural)\n#   2. Share of Wallet por canal de pagamento (rosca)\n#   3. Entradas vs. Saidas + Saldo Acumulado (apenas se outflow disponivel)\n# =============================================================================\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as mticker\nimport seaborn as sns\n\nsns.set_theme(style='whitegrid')\nCORES = {'boleto': '#ff9f43', 'credit_card': '#54a0ff', 'debit_card': '#2ecc71', 'voucher': '#ee5253'}\n\n# Grafico 1: Serie Temporal com Media Movel\n# A media movel suaviza a volatilidade intrassemanal e evidencia a tendencia.\ndf_relatorio_caixa['MM_7d'] = (\n    df_relatorio_caixa['total_entradas_BRL'].rolling(window=7, min_periods=1).mean()\n)\n\nfig1, ax1 = plt.subplots(figsize=(16, 6))\nax1.fill_between(df_relatorio_caixa.index, df_relatorio_caixa['total_entradas_BRL'],\n                 color='#54a0ff', alpha=0.15)\nax1.plot(df_relatorio_caixa.index, df_relatorio_caixa['total_entradas_BRL'],\n         color='lightgray', alpha=0.6, linewidth=1, label='Inflow Diario')\nax1.plot(df_relatorio_caixa.index, df_relatorio_caixa['MM_7d'],\n         color='#1f77b4', linewidth=2.5, label='Media Movel 7 dias')\nax1.set_title('Evolucao do Cash Inflow Diario', fontsize=15, fontweight='bold', pad=15)\nax1.set_xlabel('Data de Recebimento', fontsize=11)\nax1.set_ylabel('Volume Financeiro (R$)', fontsize=11)\nax1.xaxis.set_major_formatter(mdates.DateFormatter('%b/%Y'))\nax1.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\nax1.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'R${x/1000:.0f}k'))\nax1.set_xlim(df_relatorio_caixa.index.min(), df_relatorio_caixa.index.max())\nax1.legend(loc='upper left', fontsize=11)\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Grafico 2: Share of Wallet\ncanais  = [c for c in ['boleto', 'credit_card', 'debit_card', 'voucher'] if c in df_relatorio_caixa.columns]\nsomas   = df_relatorio_caixa[canais].sum()\ntotal_v = somas.sum()\nlabels  = [f'{c}\\n({v/total_v*100:.1f}%)' for c, v in zip(canais, somas)]\ncores   = [CORES.get(c, '#aaa') for c in canais]\n\nfig2, ax2 = plt.subplots(figsize=(8, 6))\nwedges, _ = ax2.pie(somas, startangle=90, colors=cores,\n                    wedgeprops=dict(width=0.45, edgecolor='white', linewidth=2))\nax2.legend(wedges, labels, title='Canal', loc='center left',\n           bbox_to_anchor=(1.0, 0.5), fontsize=11, title_fontsize=12, frameon=False)\nax2.set_title('Share of Wallet: Composicao do Inflow por Canal',\n              fontsize=14, fontweight='bold', pad=20)\nplt.tight_layout()\nplt.show()\n\n# Grafico 3: Entradas vs. Saidas + Saldo Acumulado\nif _outflow_ok:\n    fig3, axes = plt.subplots(2, 1, figsize=(16, 10), sharex=True,\n                              gridspec_kw={'hspace': 0.08})\n\n    axes[0].fill_between(df_saldo.index,  df_saldo['total_entradas_BRL'],\n                         alpha=0.5, color='#2ecc71', label='Entradas (Inflow)')\n    axes[0].fill_between(df_saldo.index, -df_saldo['total_saidas_BRL'],\n                         alpha=0.5, color='#ee5253', label='Saidas Estimadas (Outflow)')\n    axes[0].axhline(0, color='black', linewidth=0.8)\n    axes[0].set_title('Fluxo de Caixa Diario: Entradas vs. Saidas',\n                      fontsize=13, fontweight='bold')\n    axes[0].set_ylabel('Volume (R$)')\n    axes[0].legend(fontsize=11)\n    axes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'R${x/1000:.0f}k'))\n\n    axes[1].plot(df_saldo.index, df_saldo['saldo_acumulado_BRL'],\n                 color='#1f77b4', linewidth=2, label='Saldo Acumulado')\n    axes[1].fill_between(df_saldo.index, df_saldo['saldo_acumulado_BRL'], 0,\n                         where=(df_saldo['saldo_acumulado_BRL'] >= 0),\n                         alpha=0.2, color='#2ecc71')\n    axes[1].fill_between(df_saldo.index, df_saldo['saldo_acumulado_BRL'], 0,\n                         where=(df_saldo['saldo_acumulado_BRL'] < 0),\n                         alpha=0.2, color='#ee5253')\n    axes[1].axhline(0, color='black', linewidth=0.8, linestyle='--')\n    axes[1].set_title('Posicao de Liquidez Acumulada', fontsize=13, fontweight='bold')\n    axes[1].set_ylabel('Saldo Acumulado (R$)')\n    axes[1].legend(fontsize=11)\n    axes[1].xaxis.set_major_formatter(mdates.DateFormatter('%b/%Y'))\n    axes[1].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n    axes[1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'R${x/1e6:.1f}M'))\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 8: Modelagem Preditiva de Fluxo de Caixa (Holt-Winters)\n# =============================================================================\n# Modelo: Suavizacao Exponencial Tripla (Holt-Winters)\n#   Tendência   : aditiva — captura crescimento/queda linear da serie\n#   Sazonalidade: aditiva, periodo 7 — padrao semanal de compensacao\n#                 bancaria (boletos concentram recebimentos em dias uteis)\n#\n# JUSTIFICATIVA DA DATA DE CORTE (31/07/2018)\n#   O dataset se estende ate 2020, mas os registros pos-2018 correspondem\n#   apenas a recebiveis de parcelamentos antigos. O pico operacional ocorre\n#   ate julho/2018, garantindo serie de treino estatisticamente representativa.\n#\n# LIMITACAO CONHECIDA\n#   Zeros introduzidos em dias sem movimentacao (fill_value=0) distorcem\n#   a componente sazonal. Alternativas: agregacao semanal ou modelo de\n#   Croston para series intermitentes.\n# =============================================================================\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nimport warnings\nwarnings.filterwarnings('ignore')\n\nts = df_relatorio_caixa['total_entradas_BRL'].copy()\nts.index = pd.to_datetime(ts.index)\nts = ts.asfreq('D', fill_value=0)\n\nDATA_CORTE  = pd.to_datetime('2018-07-31')\nDATA_TREINO = DATA_CORTE - pd.Timedelta(days=365)\nts_treino   = ts[DATA_TREINO:DATA_CORTE]\n\nprint(f'Periodo de treino : {DATA_TREINO.date()} -> {DATA_CORTE.date()} ({len(ts_treino)} dias)')\nprint(f'Media diaria      : R$ {ts_treino.mean():,.2f}')\nprint(f'Dias zerados      : {(ts_treino == 0).sum()} ({(ts_treino == 0).mean()*100:.1f}%)\\n')\n\nmodelo    = ExponentialSmoothing(ts_treino, trend='add', seasonal='add', seasonal_periods=7)\nresultado = modelo.fit(optimized=True)\n\nprint(f'Alpha (nivel)       : {resultado.params[\"smoothing_level\"]:.4f}')\nprint(f'Beta  (tendencia)   : {resultado.params[\"smoothing_trend\"]:.4f}')\nprint(f'Gamma (sazonalidade): {resultado.params[\"smoothing_seasonal\"]:.4f}\\n')\n\nN            = 30\nprevisao_30d = resultado.forecast(N).clip(lower=0)\n\n# Bandas de incerteza — bootstrap de residuos, confianca 90%\n# Banda inferior: reserva minima de capital de giro\n# Banda superior: necessidade maxima de liquidez\nstd_res   = resultado.resid.std()\nZ90       = 1.645\nbanda_sup = (previsao_30d + Z90 * std_res).clip(lower=0)\nbanda_inf = (previsao_30d - Z90 * std_res).clip(lower=0)\n\nfig, ax = plt.subplots(figsize=(16, 6))\nax.plot(ts_treino.index[-90:], ts_treino[-90:],\n        color='#1f77b4', linewidth=2, label='Caixa Realizado (Ultimos 90 dias)')\nax.plot(previsao_30d.index, previsao_30d,\n        color='#ff7f0e', linewidth=2.5, linestyle='--', label='Previsao Central')\nax.fill_between(previsao_30d.index, banda_inf, banda_sup,\n                alpha=0.25, color='#ff7f0e', label='IC 90%')\nax.axvline(DATA_CORTE, color='black', linestyle=':', alpha=0.6,\n           label=f'Referencia: {DATA_CORTE.date()}')\nax.set_title('Forecast de Tesouraria — Proximos 30 Dias', fontsize=15, fontweight='bold', pad=15)\nax.set_xlabel('Data', fontsize=11)\nax.set_ylabel('Volume Financeiro Projetado (R$)', fontsize=11)\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%b'))\nax.legend(loc='upper left', fontsize=11)\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\nprint('=' * 70)\nprint(f'RELATORIO PREDITIVO DE LIQUIDEZ — PROXIMOS {N} DIAS')\nprint('=' * 70)\nprint(f'  Cenario Central (R$): {previsao_30d.sum():>15,.2f}')\nprint(f'  Media Diaria    (R$): {previsao_30d.mean():>15,.2f}')\nprint(f'  Estimativa p10  (R$): {banda_inf.sum():>15,.2f}')\nprint(f'  Estimativa p90  (R$): {banda_sup.sum():>15,.2f}')\nprint(f'  Amplitude IC    (R$): {(banda_sup - banda_inf).mean():>15,.2f} /dia')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MÓDULO 9: Validação Estatística do Modelo — Backtesting Out-of-Sample\n# =============================================================================\n# Metodologia:\n#   O modelo foi treinado ate 31/07/2018; os dados de agosto/2018 foram\n#   retidos exclusivamente para validacao (never-seen data).\n#\n# Metricas:\n#   MAE  — erro absoluto medio em R$/dia (interpretacao direta de negocio)\n#   RMSE — penaliza erros grandes (sensivel a picos de caixa)\n#   MAPE — erro percentual medio (comparavel entre horizontes/series)\n#\n# Benchmark Naive:\n#   Replica o valor do dia anterior como previsao.\n#   Qualquer modelo com valor preditivo real deve superar este baseline.\n# =============================================================================\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nD_INI = previsao_30d.index.min()\nD_FIM = previsao_30d.index.max()\n\ny_real = ts[D_INI:D_FIM]\ny_prev = previsao_30d\ny_real, y_prev = y_real.align(y_prev, join='inner')\n\nmae_hw  = mean_absolute_error(y_real, y_prev)\nrmse_hw = np.sqrt(mean_squared_error(y_real, y_prev))\n\ndef calc_mape(yt, yp):\n    yt, yp = np.array(yt), np.array(yp)\n    m = yt != 0\n    return np.mean(np.abs((yt[m] - yp[m]) / yt[m])) * 100\n\nmape_hw = calc_mape(y_real, y_prev)\n\ny_naive        = ts[D_INI:D_FIM].shift(1).fillna(method='bfill')\ny_naive, y_ral = y_naive.align(y_real, join='inner')\nmae_n          = mean_absolute_error(y_ral, y_naive)\nmape_n         = calc_mape(y_ral, y_naive)\n\n# Visualizacao: Realizado vs. Previsto\nfig, ax = plt.subplots(figsize=(14, 5))\nax.bar(y_real.index, y_real.values, color='#1f77b4', alpha=0.5, label='Realizado')\nax.plot(y_prev.index, y_prev.values, color='#ff7f0e', linewidth=2.5,\n        linestyle='--', marker='o', markersize=4, label='Previsto (Holt-Winters)')\nax.fill_between(y_prev.index, banda_inf, banda_sup,\n                alpha=0.2, color='#ff7f0e', label='IC 90%')\nax.set_title('Backtesting: Realizado vs. Previsto — Agosto/2018',\n             fontsize=14, fontweight='bold')\nax.set_xlabel('Data')\nax.set_ylabel('R$')\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%b'))\nax.legend(fontsize=11)\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\nganho_mape = mape_n  - mape_hw\nganho_mae  = mae_n   - mae_hw\n\nprint('=' * 72)\nprint('BACKTESTING OUT-OF-SAMPLE — AGOSTO/2018')\nprint('=' * 72)\nprint(f'{chr(10)}{\"Metrica\":<38} {\"Holt-Winters\":>14} {\"Naive\":>14}')\nprint('-' * 72)\nprint(f'{\"MAE  — Erro Medio Absoluto (R$/dia)\":<38} {mae_hw:>14,.2f} {mae_n:>14,.2f}')\nprint(f'{\"RMSE — Erro Quadratico Medio (R$/dia)\":<38} {rmse_hw:>14,.2f} {\"—\":>14}')\nprint(f'{\"MAPE — Erro Percentual Medio (%)\":<38} {mape_hw:>14.2f} {mape_n:>14.2f}')\nprint('-' * 72)\nprint(f'{\"Ganho HW vs. Naive (MAPE, p.p.)\":<38} {ganho_mape:>+14.2f}')\nprint(f'{\"Ganho HW vs. Naive (MAE, R$/dia)\":<38} {ganho_mae:>+14.2f}')\n\nverdict = 'APROVADO' if ganho_mape > 0 else 'REVISAR — modelo nao supera o benchmark'\nprint('\\n' + '=' * 72)\nprint('INTERPRETACAO:')\nprint('=' * 72)\nprint(f'  O Holt-Winters erra em media R$ {mae_hw:,.2f}/dia ({mape_hw:.1f}% do realizado).')\nprint(f'  Frente ao Naive ({mape_n:.1f}%), entrega reducao de {ganho_mape:.1f} p.p. no MAPE')\nprint(f'  e ganho de R$ {ganho_mae:,.2f}/dia no erro absoluto.')\nprint(f'  Diagnostico: {verdict}')\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}